{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# NAFLD detection using RNA-Seq data\n",
    "\n",
    "\n",
    "__Content creators:__  Mahdi Anvari, Sadegh Rizi\n",
    "\n",
    "**University of Tehran, Department of Biotechnology**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "-tINqWBIw-iJ"
   },
   "source": [
    "# Q1 - Python section ##"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "id": "KSeWWxUN7YBS"
   },
   "outputs": [],
   "source": [
    "# Import needed libraries\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from sklearn.metrics import precision_score, recall_score\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.linear_model import LassoCV\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.manifold import TSNE\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.neural_network import MLPClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "I5zIPrS08dhc",
    "outputId": "9d599fc8-240a-46c3-bfb0-360f1cf945b8"
   },
   "outputs": [],
   "source": [
    "# Load Data\n",
    "normal_counts = pd.read_csv('Normal.counts.voom.csv')\n",
    "meta_data = pd.read_csv('meta_data.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 255
    },
    "id": "8HhR4b_A-nSN",
    "outputId": "7f011f4e-e7f7-4c93-ab55-b8b84aa60a55"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>gene</th>\n",
       "      <th>DLDR_0001</th>\n",
       "      <th>DLDR_0002</th>\n",
       "      <th>DLDR_0003</th>\n",
       "      <th>DLDR_0004</th>\n",
       "      <th>DLDR_0005</th>\n",
       "      <th>DLDR_0006</th>\n",
       "      <th>DLDR_0007</th>\n",
       "      <th>DLDR_0008</th>\n",
       "      <th>DLDR_0009</th>\n",
       "      <th>...</th>\n",
       "      <th>DLDR_0183</th>\n",
       "      <th>DLDR_0184</th>\n",
       "      <th>DLDR_0185</th>\n",
       "      <th>DLDR_0186</th>\n",
       "      <th>DLDR_0187</th>\n",
       "      <th>DLDR_0188</th>\n",
       "      <th>DLDR_0189</th>\n",
       "      <th>DLDR_0190</th>\n",
       "      <th>DLDR_0191</th>\n",
       "      <th>DLDR_0192</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>ENSG00000000003</td>\n",
       "      <td>5.965571</td>\n",
       "      <td>5.741587</td>\n",
       "      <td>5.996891</td>\n",
       "      <td>5.551919</td>\n",
       "      <td>6.430237</td>\n",
       "      <td>6.234619</td>\n",
       "      <td>6.071503</td>\n",
       "      <td>6.441882</td>\n",
       "      <td>5.752712</td>\n",
       "      <td>...</td>\n",
       "      <td>6.304802</td>\n",
       "      <td>6.576246</td>\n",
       "      <td>6.735760</td>\n",
       "      <td>6.344234</td>\n",
       "      <td>6.608924</td>\n",
       "      <td>6.480745</td>\n",
       "      <td>6.360397</td>\n",
       "      <td>6.367705</td>\n",
       "      <td>6.604050</td>\n",
       "      <td>6.514539</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>ENSG00000000005</td>\n",
       "      <td>1.612375</td>\n",
       "      <td>2.147793</td>\n",
       "      <td>0.418542</td>\n",
       "      <td>0.702492</td>\n",
       "      <td>1.215978</td>\n",
       "      <td>0.920810</td>\n",
       "      <td>0.458163</td>\n",
       "      <td>0.927224</td>\n",
       "      <td>1.089389</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.031596</td>\n",
       "      <td>-1.091275</td>\n",
       "      <td>-0.942637</td>\n",
       "      <td>-0.026585</td>\n",
       "      <td>-0.757399</td>\n",
       "      <td>-1.083676</td>\n",
       "      <td>0.886550</td>\n",
       "      <td>-0.902201</td>\n",
       "      <td>-0.865036</td>\n",
       "      <td>-1.588749</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>ENSG00000000419</td>\n",
       "      <td>4.133821</td>\n",
       "      <td>4.120969</td>\n",
       "      <td>4.086129</td>\n",
       "      <td>4.116240</td>\n",
       "      <td>4.393797</td>\n",
       "      <td>4.390909</td>\n",
       "      <td>4.148242</td>\n",
       "      <td>4.554655</td>\n",
       "      <td>4.203819</td>\n",
       "      <td>...</td>\n",
       "      <td>4.176599</td>\n",
       "      <td>4.244459</td>\n",
       "      <td>4.342765</td>\n",
       "      <td>4.179319</td>\n",
       "      <td>4.274450</td>\n",
       "      <td>4.361634</td>\n",
       "      <td>4.093280</td>\n",
       "      <td>4.148010</td>\n",
       "      <td>4.351489</td>\n",
       "      <td>3.859711</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>ENSG00000000457</td>\n",
       "      <td>4.111056</td>\n",
       "      <td>3.922234</td>\n",
       "      <td>3.964871</td>\n",
       "      <td>3.978350</td>\n",
       "      <td>4.018235</td>\n",
       "      <td>3.864521</td>\n",
       "      <td>4.263119</td>\n",
       "      <td>3.896271</td>\n",
       "      <td>4.139546</td>\n",
       "      <td>...</td>\n",
       "      <td>4.378342</td>\n",
       "      <td>4.453838</td>\n",
       "      <td>4.685598</td>\n",
       "      <td>4.438796</td>\n",
       "      <td>4.042577</td>\n",
       "      <td>4.313540</td>\n",
       "      <td>4.205119</td>\n",
       "      <td>4.506058</td>\n",
       "      <td>4.072137</td>\n",
       "      <td>4.341988</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>ENSG00000000460</td>\n",
       "      <td>4.150662</td>\n",
       "      <td>3.732756</td>\n",
       "      <td>3.634637</td>\n",
       "      <td>3.853979</td>\n",
       "      <td>3.614220</td>\n",
       "      <td>3.500857</td>\n",
       "      <td>4.000565</td>\n",
       "      <td>4.016287</td>\n",
       "      <td>3.904500</td>\n",
       "      <td>...</td>\n",
       "      <td>2.974209</td>\n",
       "      <td>3.720038</td>\n",
       "      <td>4.640011</td>\n",
       "      <td>3.814717</td>\n",
       "      <td>2.126408</td>\n",
       "      <td>3.120196</td>\n",
       "      <td>3.336802</td>\n",
       "      <td>3.982071</td>\n",
       "      <td>3.143138</td>\n",
       "      <td>2.741172</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 193 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "              gene  DLDR_0001  DLDR_0002  DLDR_0003  DLDR_0004  DLDR_0005  \\\n",
       "0  ENSG00000000003   5.965571   5.741587   5.996891   5.551919   6.430237   \n",
       "1  ENSG00000000005   1.612375   2.147793   0.418542   0.702492   1.215978   \n",
       "2  ENSG00000000419   4.133821   4.120969   4.086129   4.116240   4.393797   \n",
       "3  ENSG00000000457   4.111056   3.922234   3.964871   3.978350   4.018235   \n",
       "4  ENSG00000000460   4.150662   3.732756   3.634637   3.853979   3.614220   \n",
       "\n",
       "   DLDR_0006  DLDR_0007  DLDR_0008  DLDR_0009  ...  DLDR_0183  DLDR_0184  \\\n",
       "0   6.234619   6.071503   6.441882   5.752712  ...   6.304802   6.576246   \n",
       "1   0.920810   0.458163   0.927224   1.089389  ...  -0.031596  -1.091275   \n",
       "2   4.390909   4.148242   4.554655   4.203819  ...   4.176599   4.244459   \n",
       "3   3.864521   4.263119   3.896271   4.139546  ...   4.378342   4.453838   \n",
       "4   3.500857   4.000565   4.016287   3.904500  ...   2.974209   3.720038   \n",
       "\n",
       "   DLDR_0185  DLDR_0186  DLDR_0187  DLDR_0188  DLDR_0189  DLDR_0190  \\\n",
       "0   6.735760   6.344234   6.608924   6.480745   6.360397   6.367705   \n",
       "1  -0.942637  -0.026585  -0.757399  -1.083676   0.886550  -0.902201   \n",
       "2   4.342765   4.179319   4.274450   4.361634   4.093280   4.148010   \n",
       "3   4.685598   4.438796   4.042577   4.313540   4.205119   4.506058   \n",
       "4   4.640011   3.814717   2.126408   3.120196   3.336802   3.982071   \n",
       "\n",
       "   DLDR_0191  DLDR_0192  \n",
       "0   6.604050   6.514539  \n",
       "1  -0.865036  -1.588749  \n",
       "2   4.351489   3.859711  \n",
       "3   4.072137   4.341988  \n",
       "4   3.143138   2.741172  \n",
       "\n",
       "[5 rows x 193 columns]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "normal_counts.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "mMe2Ge-2AICA",
    "outputId": "45d4a2ff-3055-4bc4-fbe7-fe434dae9448"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(17396, 193)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "normal_counts.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "there are 192 samples with 17396 features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 206
    },
    "id": "9yw90VVg9xwt",
    "outputId": "fe4f5b78-4e77-4326-b290-89a5d170008d"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Patient_ID</th>\n",
       "      <th>SEX</th>\n",
       "      <th>BMI_surg</th>\n",
       "      <th>Age</th>\n",
       "      <th>Run</th>\n",
       "      <th>Diabet</th>\n",
       "      <th>Simplified_class</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>DLDR_0001</td>\n",
       "      <td>Female</td>\n",
       "      <td>35.214555</td>\n",
       "      <td>55</td>\n",
       "      <td>SRR8378590</td>\n",
       "      <td>Non Diabetic</td>\n",
       "      <td>Normal</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>DLDR_0002</td>\n",
       "      <td>Female</td>\n",
       "      <td>39.421748</td>\n",
       "      <td>47</td>\n",
       "      <td>SRR8378589</td>\n",
       "      <td>Diabetic</td>\n",
       "      <td>Normal</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>DLDR_0003</td>\n",
       "      <td>Male</td>\n",
       "      <td>48.758108</td>\n",
       "      <td>46</td>\n",
       "      <td>SRR8378432</td>\n",
       "      <td>Non Diabetic</td>\n",
       "      <td>Normal</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>DLDR_0004</td>\n",
       "      <td>Female</td>\n",
       "      <td>41.822607</td>\n",
       "      <td>36</td>\n",
       "      <td>SRR8378431</td>\n",
       "      <td>Non Diabetic</td>\n",
       "      <td>Normal</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>DLDR_0005</td>\n",
       "      <td>Female</td>\n",
       "      <td>53.582192</td>\n",
       "      <td>54</td>\n",
       "      <td>SRR8378434</td>\n",
       "      <td>Non Diabetic</td>\n",
       "      <td>Normal</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  Patient_ID     SEX   BMI_surg  Age         Run        Diabet  \\\n",
       "0  DLDR_0001  Female  35.214555   55  SRR8378590  Non Diabetic   \n",
       "1  DLDR_0002  Female  39.421748   47  SRR8378589      Diabetic   \n",
       "2  DLDR_0003    Male  48.758108   46  SRR8378432  Non Diabetic   \n",
       "3  DLDR_0004  Female  41.822607   36  SRR8378431  Non Diabetic   \n",
       "4  DLDR_0005  Female  53.582192   54  SRR8378434  Non Diabetic   \n",
       "\n",
       "  Simplified_class  \n",
       "0           Normal  \n",
       "1           Normal  \n",
       "2           Normal  \n",
       "3           Normal  \n",
       "4           Normal  "
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "meta_data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "1iOVAvhSATlU",
    "outputId": "62c226b5-f769-40ce-e858-b8431dee48d7"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(192, 7)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "meta_data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "4294TsWRGJNP",
    "outputId": "f3af3c86-ed4b-4557-c722-eefc2b5bf7c2"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of Normal samples:  74\n",
      "Number of Non_advanced_Fibrosis samples:  53\n",
      "Number of Advanced_fibrosis:  65\n"
     ]
    }
   ],
   "source": [
    "print(\"Number of Normal samples: \", meta_data['Simplified_class'].to_list().count(\"Normal\"))\n",
    "print(\"Number of Non_advanced_Fibrosis samples: \", meta_data['Simplified_class'].to_list().count(\"Non_advanced_Fibrosis\"))\n",
    "print(\"Number of Advanced_fibrosis: \", meta_data['Simplified_class'].to_list().count(\"Advanced_fibrosis\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's split our data and labels to train and test sets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(normal_counts.iloc[0:,1:].T, meta_data['Simplified_class'], test_size=0.3, random_state = 10101)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>...</th>\n",
       "      <th>17386</th>\n",
       "      <th>17387</th>\n",
       "      <th>17388</th>\n",
       "      <th>17389</th>\n",
       "      <th>17390</th>\n",
       "      <th>17391</th>\n",
       "      <th>17392</th>\n",
       "      <th>17393</th>\n",
       "      <th>17394</th>\n",
       "      <th>17395</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>DLDR_0036</th>\n",
       "      <td>5.820135</td>\n",
       "      <td>-1.060061</td>\n",
       "      <td>4.388400</td>\n",
       "      <td>4.080172</td>\n",
       "      <td>2.564430</td>\n",
       "      <td>3.552685</td>\n",
       "      <td>11.011379</td>\n",
       "      <td>4.682305</td>\n",
       "      <td>6.951539</td>\n",
       "      <td>4.589555</td>\n",
       "      <td>...</td>\n",
       "      <td>4.851631</td>\n",
       "      <td>-0.719024</td>\n",
       "      <td>-0.719024</td>\n",
       "      <td>-1.266512</td>\n",
       "      <td>-0.323095</td>\n",
       "      <td>3.157170</td>\n",
       "      <td>0.459313</td>\n",
       "      <td>3.115198</td>\n",
       "      <td>-2.645023</td>\n",
       "      <td>0.760969</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>DLDR_0081</th>\n",
       "      <td>6.546299</td>\n",
       "      <td>0.582165</td>\n",
       "      <td>3.752090</td>\n",
       "      <td>4.645175</td>\n",
       "      <td>3.840899</td>\n",
       "      <td>3.201075</td>\n",
       "      <td>11.433579</td>\n",
       "      <td>3.705547</td>\n",
       "      <td>7.143316</td>\n",
       "      <td>5.482169</td>\n",
       "      <td>...</td>\n",
       "      <td>5.050934</td>\n",
       "      <td>1.681701</td>\n",
       "      <td>-0.640228</td>\n",
       "      <td>0.096738</td>\n",
       "      <td>0.582165</td>\n",
       "      <td>4.041596</td>\n",
       "      <td>0.096738</td>\n",
       "      <td>2.418666</td>\n",
       "      <td>-2.225190</td>\n",
       "      <td>0.582165</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>DLDR_0191</th>\n",
       "      <td>6.604050</td>\n",
       "      <td>-0.865036</td>\n",
       "      <td>4.351489</td>\n",
       "      <td>4.072137</td>\n",
       "      <td>3.143138</td>\n",
       "      <td>4.037476</td>\n",
       "      <td>11.782524</td>\n",
       "      <td>4.358527</td>\n",
       "      <td>8.468526</td>\n",
       "      <td>5.013154</td>\n",
       "      <td>...</td>\n",
       "      <td>5.112244</td>\n",
       "      <td>-2.002540</td>\n",
       "      <td>-0.076540</td>\n",
       "      <td>-1.154543</td>\n",
       "      <td>-0.624028</td>\n",
       "      <td>2.050571</td>\n",
       "      <td>-1.517113</td>\n",
       "      <td>2.084923</td>\n",
       "      <td>-4.324468</td>\n",
       "      <td>0.067849</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>DLDR_0188</th>\n",
       "      <td>6.480745</td>\n",
       "      <td>-1.083676</td>\n",
       "      <td>4.361634</td>\n",
       "      <td>4.313540</td>\n",
       "      <td>3.120196</td>\n",
       "      <td>1.941859</td>\n",
       "      <td>11.451981</td>\n",
       "      <td>4.556052</td>\n",
       "      <td>7.183779</td>\n",
       "      <td>5.066071</td>\n",
       "      <td>...</td>\n",
       "      <td>5.204366</td>\n",
       "      <td>2.086249</td>\n",
       "      <td>0.501286</td>\n",
       "      <td>0.632531</td>\n",
       "      <td>-0.431600</td>\n",
       "      <td>2.616763</td>\n",
       "      <td>1.063165</td>\n",
       "      <td>1.941859</td>\n",
       "      <td>-2.306069</td>\n",
       "      <td>0.632531</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>DLDR_0130</th>\n",
       "      <td>6.550016</td>\n",
       "      <td>-1.222374</td>\n",
       "      <td>4.534941</td>\n",
       "      <td>4.370763</td>\n",
       "      <td>3.512952</td>\n",
       "      <td>2.517867</td>\n",
       "      <td>12.041229</td>\n",
       "      <td>4.315374</td>\n",
       "      <td>7.485927</td>\n",
       "      <td>4.655817</td>\n",
       "      <td>...</td>\n",
       "      <td>5.519093</td>\n",
       "      <td>-0.037949</td>\n",
       "      <td>-0.289488</td>\n",
       "      <td>-1.874450</td>\n",
       "      <td>-0.981365</td>\n",
       "      <td>2.594319</td>\n",
       "      <td>0.447478</td>\n",
       "      <td>2.556600</td>\n",
       "      <td>-2.359877</td>\n",
       "      <td>0.932905</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 17396 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "              0         1         2         3         4         5      \\\n",
       "DLDR_0036  5.820135 -1.060061  4.388400  4.080172  2.564430  3.552685   \n",
       "DLDR_0081  6.546299  0.582165  3.752090  4.645175  3.840899  3.201075   \n",
       "DLDR_0191  6.604050 -0.865036  4.351489  4.072137  3.143138  4.037476   \n",
       "DLDR_0188  6.480745 -1.083676  4.361634  4.313540  3.120196  1.941859   \n",
       "DLDR_0130  6.550016 -1.222374  4.534941  4.370763  3.512952  2.517867   \n",
       "\n",
       "               6         7         8         9      ...     17386     17387  \\\n",
       "DLDR_0036  11.011379  4.682305  6.951539  4.589555  ...  4.851631 -0.719024   \n",
       "DLDR_0081  11.433579  3.705547  7.143316  5.482169  ...  5.050934  1.681701   \n",
       "DLDR_0191  11.782524  4.358527  8.468526  5.013154  ...  5.112244 -2.002540   \n",
       "DLDR_0188  11.451981  4.556052  7.183779  5.066071  ...  5.204366  2.086249   \n",
       "DLDR_0130  12.041229  4.315374  7.485927  4.655817  ...  5.519093 -0.037949   \n",
       "\n",
       "              17388     17389     17390     17391     17392     17393  \\\n",
       "DLDR_0036 -0.719024 -1.266512 -0.323095  3.157170  0.459313  3.115198   \n",
       "DLDR_0081 -0.640228  0.096738  0.582165  4.041596  0.096738  2.418666   \n",
       "DLDR_0191 -0.076540 -1.154543 -0.624028  2.050571 -1.517113  2.084923   \n",
       "DLDR_0188  0.501286  0.632531 -0.431600  2.616763  1.063165  1.941859   \n",
       "DLDR_0130 -0.289488 -1.874450 -0.981365  2.594319  0.447478  2.556600   \n",
       "\n",
       "              17394     17395  \n",
       "DLDR_0036 -2.645023  0.760969  \n",
       "DLDR_0081 -2.225190  0.582165  \n",
       "DLDR_0191 -4.324468  0.067849  \n",
       "DLDR_0188 -2.306069  0.632531  \n",
       "DLDR_0130 -2.359877  0.932905  \n",
       "\n",
       "[5 rows x 17396 columns]"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(134, 17396)"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "35                    Normal\n",
       "80         Advanced_fibrosis\n",
       "190                   Normal\n",
       "187                   Normal\n",
       "129    Non_advanced_Fibrosis\n",
       "Name: Simplified_class, dtype: object"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(134,)"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_train.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Labels distribution in train set:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of Normal samples:  44\n",
      "Number of Non_advanced_Fibrosis samples:  38\n",
      "Number of Advanced_fibrosis samples:  52\n"
     ]
    }
   ],
   "source": [
    "print(\"Number of Normal samples: \", y_train.to_list().count(\"Normal\"))\n",
    "print(\"Number of Non_advanced_Fibrosis samples: \", y_train.to_list().count(\"Non_advanced_Fibrosis\"))\n",
    "print(\"Number of Advanced_fibrosis samples: \", y_train.to_list().count(\"Advanced_fibrosis\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, letâ€™s save the training set data to use in the R Jupyter Notebook for feature selection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train.T.to_csv('train_normal_counts.csv', index=False)\n",
    "y_train.T.to_csv('train_meta_data.csv', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Run R Jupyter Notebook"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's load the output of R to continue the task"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "subset_data = pd.read_csv('subset_data.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>DLDR_0036</th>\n",
       "      <th>DLDR_0081</th>\n",
       "      <th>DLDR_0191</th>\n",
       "      <th>DLDR_0188</th>\n",
       "      <th>DLDR_0130</th>\n",
       "      <th>DLDR_0013</th>\n",
       "      <th>DLDR_0079</th>\n",
       "      <th>DLDR_0131</th>\n",
       "      <th>DLDR_0135</th>\n",
       "      <th>...</th>\n",
       "      <th>DLDR_0175</th>\n",
       "      <th>DLDR_0052</th>\n",
       "      <th>DLDR_0087</th>\n",
       "      <th>DLDR_0155</th>\n",
       "      <th>DLDR_0092</th>\n",
       "      <th>DLDR_0187</th>\n",
       "      <th>DLDR_0186</th>\n",
       "      <th>DLDR_0179</th>\n",
       "      <th>DLDR_0182</th>\n",
       "      <th>DLDR_0001</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>10</td>\n",
       "      <td>4.589555</td>\n",
       "      <td>5.482169</td>\n",
       "      <td>5.013154</td>\n",
       "      <td>5.066071</td>\n",
       "      <td>4.655817</td>\n",
       "      <td>4.299078</td>\n",
       "      <td>4.752957</td>\n",
       "      <td>5.409514</td>\n",
       "      <td>4.993777</td>\n",
       "      <td>...</td>\n",
       "      <td>4.853565</td>\n",
       "      <td>4.567173</td>\n",
       "      <td>4.985158</td>\n",
       "      <td>5.234776</td>\n",
       "      <td>4.900754</td>\n",
       "      <td>4.923087</td>\n",
       "      <td>5.004500</td>\n",
       "      <td>5.058062</td>\n",
       "      <td>5.002454</td>\n",
       "      <td>4.221450</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>57</td>\n",
       "      <td>-0.719024</td>\n",
       "      <td>0.582165</td>\n",
       "      <td>-1.154543</td>\n",
       "      <td>-1.083676</td>\n",
       "      <td>-0.289488</td>\n",
       "      <td>-0.006469</td>\n",
       "      <td>-1.138550</td>\n",
       "      <td>-4.060128</td>\n",
       "      <td>-2.104255</td>\n",
       "      <td>...</td>\n",
       "      <td>-2.285986</td>\n",
       "      <td>-0.110595</td>\n",
       "      <td>-0.385647</td>\n",
       "      <td>-3.580073</td>\n",
       "      <td>0.317259</td>\n",
       "      <td>-0.757399</td>\n",
       "      <td>-3.486017</td>\n",
       "      <td>-1.346471</td>\n",
       "      <td>-1.103280</td>\n",
       "      <td>-0.005377</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>265</td>\n",
       "      <td>0.587637</td>\n",
       "      <td>-2.225190</td>\n",
       "      <td>-0.076540</td>\n",
       "      <td>0.196432</td>\n",
       "      <td>0.272391</td>\n",
       "      <td>2.523150</td>\n",
       "      <td>1.424386</td>\n",
       "      <td>0.332190</td>\n",
       "      <td>0.217673</td>\n",
       "      <td>...</td>\n",
       "      <td>1.083248</td>\n",
       "      <td>0.352377</td>\n",
       "      <td>-0.309698</td>\n",
       "      <td>0.120366</td>\n",
       "      <td>0.890444</td>\n",
       "      <td>-0.291735</td>\n",
       "      <td>0.811664</td>\n",
       "      <td>-0.246936</td>\n",
       "      <td>0.416094</td>\n",
       "      <td>2.729099</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>275</td>\n",
       "      <td>1.662405</td>\n",
       "      <td>2.529697</td>\n",
       "      <td>1.508422</td>\n",
       "      <td>1.991612</td>\n",
       "      <td>1.467942</td>\n",
       "      <td>1.934152</td>\n",
       "      <td>2.031375</td>\n",
       "      <td>2.048397</td>\n",
       "      <td>0.528013</td>\n",
       "      <td>...</td>\n",
       "      <td>1.083248</td>\n",
       "      <td>2.556469</td>\n",
       "      <td>2.055951</td>\n",
       "      <td>1.374123</td>\n",
       "      <td>1.902221</td>\n",
       "      <td>1.838969</td>\n",
       "      <td>1.643266</td>\n",
       "      <td>1.272439</td>\n",
       "      <td>1.932344</td>\n",
       "      <td>2.467558</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>278</td>\n",
       "      <td>5.529902</td>\n",
       "      <td>5.846272</td>\n",
       "      <td>5.553583</td>\n",
       "      <td>5.359267</td>\n",
       "      <td>5.774549</td>\n",
       "      <td>4.962662</td>\n",
       "      <td>5.201300</td>\n",
       "      <td>5.500205</td>\n",
       "      <td>5.782051</td>\n",
       "      <td>...</td>\n",
       "      <td>5.862067</td>\n",
       "      <td>5.038603</td>\n",
       "      <td>5.665231</td>\n",
       "      <td>5.781140</td>\n",
       "      <td>5.745159</td>\n",
       "      <td>5.438062</td>\n",
       "      <td>5.570169</td>\n",
       "      <td>5.558701</td>\n",
       "      <td>5.733822</td>\n",
       "      <td>5.220121</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>522</th>\n",
       "      <td>16863</td>\n",
       "      <td>3.811126</td>\n",
       "      <td>3.329399</td>\n",
       "      <td>2.183327</td>\n",
       "      <td>2.412750</td>\n",
       "      <td>3.323819</td>\n",
       "      <td>2.690386</td>\n",
       "      <td>3.515760</td>\n",
       "      <td>3.197260</td>\n",
       "      <td>2.112975</td>\n",
       "      <td>...</td>\n",
       "      <td>1.555316</td>\n",
       "      <td>3.901539</td>\n",
       "      <td>3.344479</td>\n",
       "      <td>1.911780</td>\n",
       "      <td>3.763838</td>\n",
       "      <td>3.667268</td>\n",
       "      <td>2.742802</td>\n",
       "      <td>2.446087</td>\n",
       "      <td>3.857108</td>\n",
       "      <td>2.844001</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>523</th>\n",
       "      <td>16887</td>\n",
       "      <td>3.576080</td>\n",
       "      <td>2.418666</td>\n",
       "      <td>3.355012</td>\n",
       "      <td>3.288878</td>\n",
       "      <td>3.231084</td>\n",
       "      <td>3.757011</td>\n",
       "      <td>2.435441</td>\n",
       "      <td>3.079423</td>\n",
       "      <td>2.393996</td>\n",
       "      <td>...</td>\n",
       "      <td>2.974541</td>\n",
       "      <td>3.737944</td>\n",
       "      <td>2.476362</td>\n",
       "      <td>2.817958</td>\n",
       "      <td>2.596331</td>\n",
       "      <td>3.203431</td>\n",
       "      <td>3.162640</td>\n",
       "      <td>2.353968</td>\n",
       "      <td>3.445156</td>\n",
       "      <td>3.271068</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>524</th>\n",
       "      <td>16892</td>\n",
       "      <td>4.007463</td>\n",
       "      <td>3.060212</td>\n",
       "      <td>2.951656</td>\n",
       "      <td>3.366357</td>\n",
       "      <td>2.649112</td>\n",
       "      <td>2.774044</td>\n",
       "      <td>3.123117</td>\n",
       "      <td>2.951099</td>\n",
       "      <td>2.974696</td>\n",
       "      <td>...</td>\n",
       "      <td>2.604785</td>\n",
       "      <td>3.934981</td>\n",
       "      <td>3.001089</td>\n",
       "      <td>2.596515</td>\n",
       "      <td>3.945549</td>\n",
       "      <td>4.002569</td>\n",
       "      <td>3.359473</td>\n",
       "      <td>3.497226</td>\n",
       "      <td>3.563476</td>\n",
       "      <td>2.830128</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>525</th>\n",
       "      <td>17075</td>\n",
       "      <td>6.925971</td>\n",
       "      <td>7.323632</td>\n",
       "      <td>7.411511</td>\n",
       "      <td>7.189120</td>\n",
       "      <td>7.519400</td>\n",
       "      <td>6.661844</td>\n",
       "      <td>7.087205</td>\n",
       "      <td>7.366661</td>\n",
       "      <td>7.586092</td>\n",
       "      <td>...</td>\n",
       "      <td>7.491543</td>\n",
       "      <td>6.721953</td>\n",
       "      <td>7.511299</td>\n",
       "      <td>7.684565</td>\n",
       "      <td>7.620817</td>\n",
       "      <td>7.419428</td>\n",
       "      <td>7.417614</td>\n",
       "      <td>7.354464</td>\n",
       "      <td>7.633460</td>\n",
       "      <td>6.752731</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>526</th>\n",
       "      <td>17187</td>\n",
       "      <td>-2.645023</td>\n",
       "      <td>-2.225190</td>\n",
       "      <td>-4.324468</td>\n",
       "      <td>-3.891031</td>\n",
       "      <td>-4.681805</td>\n",
       "      <td>0.820694</td>\n",
       "      <td>-3.013019</td>\n",
       "      <td>-4.060128</td>\n",
       "      <td>-4.426183</td>\n",
       "      <td>...</td>\n",
       "      <td>-3.870949</td>\n",
       "      <td>-3.735085</td>\n",
       "      <td>-4.010138</td>\n",
       "      <td>-5.165036</td>\n",
       "      <td>-2.718365</td>\n",
       "      <td>-5.149716</td>\n",
       "      <td>-5.070979</td>\n",
       "      <td>-2.568864</td>\n",
       "      <td>-3.425208</td>\n",
       "      <td>1.202731</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>527 rows Ã— 135 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     Unnamed: 0  DLDR_0036  DLDR_0081  DLDR_0191  DLDR_0188  DLDR_0130  \\\n",
       "0            10   4.589555   5.482169   5.013154   5.066071   4.655817   \n",
       "1            57  -0.719024   0.582165  -1.154543  -1.083676  -0.289488   \n",
       "2           265   0.587637  -2.225190  -0.076540   0.196432   0.272391   \n",
       "3           275   1.662405   2.529697   1.508422   1.991612   1.467942   \n",
       "4           278   5.529902   5.846272   5.553583   5.359267   5.774549   \n",
       "..          ...        ...        ...        ...        ...        ...   \n",
       "522       16863   3.811126   3.329399   2.183327   2.412750   3.323819   \n",
       "523       16887   3.576080   2.418666   3.355012   3.288878   3.231084   \n",
       "524       16892   4.007463   3.060212   2.951656   3.366357   2.649112   \n",
       "525       17075   6.925971   7.323632   7.411511   7.189120   7.519400   \n",
       "526       17187  -2.645023  -2.225190  -4.324468  -3.891031  -4.681805   \n",
       "\n",
       "     DLDR_0013  DLDR_0079  DLDR_0131  DLDR_0135  ...  DLDR_0175  DLDR_0052  \\\n",
       "0     4.299078   4.752957   5.409514   4.993777  ...   4.853565   4.567173   \n",
       "1    -0.006469  -1.138550  -4.060128  -2.104255  ...  -2.285986  -0.110595   \n",
       "2     2.523150   1.424386   0.332190   0.217673  ...   1.083248   0.352377   \n",
       "3     1.934152   2.031375   2.048397   0.528013  ...   1.083248   2.556469   \n",
       "4     4.962662   5.201300   5.500205   5.782051  ...   5.862067   5.038603   \n",
       "..         ...        ...        ...        ...  ...        ...        ...   \n",
       "522   2.690386   3.515760   3.197260   2.112975  ...   1.555316   3.901539   \n",
       "523   3.757011   2.435441   3.079423   2.393996  ...   2.974541   3.737944   \n",
       "524   2.774044   3.123117   2.951099   2.974696  ...   2.604785   3.934981   \n",
       "525   6.661844   7.087205   7.366661   7.586092  ...   7.491543   6.721953   \n",
       "526   0.820694  -3.013019  -4.060128  -4.426183  ...  -3.870949  -3.735085   \n",
       "\n",
       "     DLDR_0087  DLDR_0155  DLDR_0092  DLDR_0187  DLDR_0186  DLDR_0179  \\\n",
       "0     4.985158   5.234776   4.900754   4.923087   5.004500   5.058062   \n",
       "1    -0.385647  -3.580073   0.317259  -0.757399  -3.486017  -1.346471   \n",
       "2    -0.309698   0.120366   0.890444  -0.291735   0.811664  -0.246936   \n",
       "3     2.055951   1.374123   1.902221   1.838969   1.643266   1.272439   \n",
       "4     5.665231   5.781140   5.745159   5.438062   5.570169   5.558701   \n",
       "..         ...        ...        ...        ...        ...        ...   \n",
       "522   3.344479   1.911780   3.763838   3.667268   2.742802   2.446087   \n",
       "523   2.476362   2.817958   2.596331   3.203431   3.162640   2.353968   \n",
       "524   3.001089   2.596515   3.945549   4.002569   3.359473   3.497226   \n",
       "525   7.511299   7.684565   7.620817   7.419428   7.417614   7.354464   \n",
       "526  -4.010138  -5.165036  -2.718365  -5.149716  -5.070979  -2.568864   \n",
       "\n",
       "     DLDR_0182  DLDR_0001  \n",
       "0     5.002454   4.221450  \n",
       "1    -1.103280  -0.005377  \n",
       "2     0.416094   2.729099  \n",
       "3     1.932344   2.467558  \n",
       "4     5.733822   5.220121  \n",
       "..         ...        ...  \n",
       "522   3.857108   2.844001  \n",
       "523   3.445156   3.271068  \n",
       "524   3.563476   2.830128  \n",
       "525   7.633460   6.752731  \n",
       "526  -3.425208   1.202731  \n",
       "\n",
       "[527 rows x 135 columns]"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "subset_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(527, 135)"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "subset_data.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We need to extract the same features for the X test dataset as well. To do this, we must identify the indices of our selected DEGs and apply the same subsetting to the test data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "selected_genes_R = subset_data.T.iloc[0,:].to_list()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "selected_genes_Python = [int(i-1) for i in selected_genes_R ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[9, 56, 264, 274, 277, 296, 309, 340, 351, 389]"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "selected_genes_Python[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "527"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(selected_genes_Python)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_deg = subset_data.iloc[0:,1:].T\n",
    "df_deg_test = X_test[selected_genes_Python]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>...</th>\n",
       "      <th>517</th>\n",
       "      <th>518</th>\n",
       "      <th>519</th>\n",
       "      <th>520</th>\n",
       "      <th>521</th>\n",
       "      <th>522</th>\n",
       "      <th>523</th>\n",
       "      <th>524</th>\n",
       "      <th>525</th>\n",
       "      <th>526</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>DLDR_0036</th>\n",
       "      <td>4.589555</td>\n",
       "      <td>-0.719024</td>\n",
       "      <td>0.587637</td>\n",
       "      <td>1.662405</td>\n",
       "      <td>5.529902</td>\n",
       "      <td>7.549487</td>\n",
       "      <td>0.318451</td>\n",
       "      <td>6.089009</td>\n",
       "      <td>5.898008</td>\n",
       "      <td>9.044188</td>\n",
       "      <td>...</td>\n",
       "      <td>3.104511</td>\n",
       "      <td>1.602904</td>\n",
       "      <td>0.915692</td>\n",
       "      <td>7.886943</td>\n",
       "      <td>5.319606</td>\n",
       "      <td>3.811126</td>\n",
       "      <td>3.576080</td>\n",
       "      <td>4.007463</td>\n",
       "      <td>6.925971</td>\n",
       "      <td>-2.645023</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>DLDR_0081</th>\n",
       "      <td>5.482169</td>\n",
       "      <td>0.582165</td>\n",
       "      <td>-2.225190</td>\n",
       "      <td>2.529697</td>\n",
       "      <td>5.846272</td>\n",
       "      <td>7.759228</td>\n",
       "      <td>0.096738</td>\n",
       "      <td>6.539682</td>\n",
       "      <td>6.101239</td>\n",
       "      <td>8.633568</td>\n",
       "      <td>...</td>\n",
       "      <td>2.819204</td>\n",
       "      <td>1.234242</td>\n",
       "      <td>-0.640228</td>\n",
       "      <td>6.310085</td>\n",
       "      <td>3.797178</td>\n",
       "      <td>3.329399</td>\n",
       "      <td>2.418666</td>\n",
       "      <td>3.060212</td>\n",
       "      <td>7.323632</td>\n",
       "      <td>-2.225190</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>DLDR_0191</th>\n",
       "      <td>5.013154</td>\n",
       "      <td>-1.154543</td>\n",
       "      <td>-0.076540</td>\n",
       "      <td>1.508422</td>\n",
       "      <td>5.553583</td>\n",
       "      <td>7.612538</td>\n",
       "      <td>1.033084</td>\n",
       "      <td>6.434588</td>\n",
       "      <td>6.098648</td>\n",
       "      <td>8.244201</td>\n",
       "      <td>...</td>\n",
       "      <td>2.275445</td>\n",
       "      <td>0.884985</td>\n",
       "      <td>0.067849</td>\n",
       "      <td>7.139567</td>\n",
       "      <td>3.909152</td>\n",
       "      <td>2.183327</td>\n",
       "      <td>3.355012</td>\n",
       "      <td>2.951656</td>\n",
       "      <td>7.411511</td>\n",
       "      <td>-4.324468</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>DLDR_0188</th>\n",
       "      <td>5.066071</td>\n",
       "      <td>-1.083676</td>\n",
       "      <td>0.196432</td>\n",
       "      <td>1.991612</td>\n",
       "      <td>5.359267</td>\n",
       "      <td>8.070057</td>\n",
       "      <td>0.356896</td>\n",
       "      <td>6.476384</td>\n",
       "      <td>6.118797</td>\n",
       "      <td>7.951712</td>\n",
       "      <td>...</td>\n",
       "      <td>2.708882</td>\n",
       "      <td>0.356896</td>\n",
       "      <td>-0.431600</td>\n",
       "      <td>7.167637</td>\n",
       "      <td>4.021858</td>\n",
       "      <td>2.412750</td>\n",
       "      <td>3.288878</td>\n",
       "      <td>3.366357</td>\n",
       "      <td>7.189120</td>\n",
       "      <td>-3.891031</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>DLDR_0130</th>\n",
       "      <td>4.655817</td>\n",
       "      <td>-0.289488</td>\n",
       "      <td>0.272391</td>\n",
       "      <td>1.467942</td>\n",
       "      <td>5.774549</td>\n",
       "      <td>7.439405</td>\n",
       "      <td>0.362589</td>\n",
       "      <td>6.486240</td>\n",
       "      <td>6.239292</td>\n",
       "      <td>8.248378</td>\n",
       "      <td>...</td>\n",
       "      <td>2.969247</td>\n",
       "      <td>1.248932</td>\n",
       "      <td>-1.222374</td>\n",
       "      <td>6.106913</td>\n",
       "      <td>3.570860</td>\n",
       "      <td>3.323819</td>\n",
       "      <td>3.231084</td>\n",
       "      <td>2.649112</td>\n",
       "      <td>7.519400</td>\n",
       "      <td>-4.681805</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 527 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                0         1         2         3         4         5    \\\n",
       "DLDR_0036  4.589555 -0.719024  0.587637  1.662405  5.529902  7.549487   \n",
       "DLDR_0081  5.482169  0.582165 -2.225190  2.529697  5.846272  7.759228   \n",
       "DLDR_0191  5.013154 -1.154543 -0.076540  1.508422  5.553583  7.612538   \n",
       "DLDR_0188  5.066071 -1.083676  0.196432  1.991612  5.359267  8.070057   \n",
       "DLDR_0130  4.655817 -0.289488  0.272391  1.467942  5.774549  7.439405   \n",
       "\n",
       "                6         7         8         9    ...       517       518  \\\n",
       "DLDR_0036  0.318451  6.089009  5.898008  9.044188  ...  3.104511  1.602904   \n",
       "DLDR_0081  0.096738  6.539682  6.101239  8.633568  ...  2.819204  1.234242   \n",
       "DLDR_0191  1.033084  6.434588  6.098648  8.244201  ...  2.275445  0.884985   \n",
       "DLDR_0188  0.356896  6.476384  6.118797  7.951712  ...  2.708882  0.356896   \n",
       "DLDR_0130  0.362589  6.486240  6.239292  8.248378  ...  2.969247  1.248932   \n",
       "\n",
       "                519       520       521       522       523       524  \\\n",
       "DLDR_0036  0.915692  7.886943  5.319606  3.811126  3.576080  4.007463   \n",
       "DLDR_0081 -0.640228  6.310085  3.797178  3.329399  2.418666  3.060212   \n",
       "DLDR_0191  0.067849  7.139567  3.909152  2.183327  3.355012  2.951656   \n",
       "DLDR_0188 -0.431600  7.167637  4.021858  2.412750  3.288878  3.366357   \n",
       "DLDR_0130 -1.222374  6.106913  3.570860  3.323819  3.231084  2.649112   \n",
       "\n",
       "                525       526  \n",
       "DLDR_0036  6.925971 -2.645023  \n",
       "DLDR_0081  7.323632 -2.225190  \n",
       "DLDR_0191  7.411511 -4.324468  \n",
       "DLDR_0188  7.189120 -3.891031  \n",
       "DLDR_0130  7.519400 -4.681805  \n",
       "\n",
       "[5 rows x 527 columns]"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_deg.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>9</th>\n",
       "      <th>56</th>\n",
       "      <th>264</th>\n",
       "      <th>274</th>\n",
       "      <th>277</th>\n",
       "      <th>296</th>\n",
       "      <th>309</th>\n",
       "      <th>340</th>\n",
       "      <th>351</th>\n",
       "      <th>389</th>\n",
       "      <th>...</th>\n",
       "      <th>16641</th>\n",
       "      <th>16686</th>\n",
       "      <th>16715</th>\n",
       "      <th>16731</th>\n",
       "      <th>16762</th>\n",
       "      <th>16862</th>\n",
       "      <th>16886</th>\n",
       "      <th>16891</th>\n",
       "      <th>17074</th>\n",
       "      <th>17186</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>DLDR_0022</th>\n",
       "      <td>3.967031</td>\n",
       "      <td>0.177378</td>\n",
       "      <td>2.880522</td>\n",
       "      <td>2.254454</td>\n",
       "      <td>5.101756</td>\n",
       "      <td>7.696151</td>\n",
       "      <td>2.077214</td>\n",
       "      <td>5.845657</td>\n",
       "      <td>5.444621</td>\n",
       "      <td>8.076772</td>\n",
       "      <td>...</td>\n",
       "      <td>2.825450</td>\n",
       "      <td>0.246091</td>\n",
       "      <td>0.928350</td>\n",
       "      <td>7.735892</td>\n",
       "      <td>4.644785</td>\n",
       "      <td>2.335526</td>\n",
       "      <td>3.460071</td>\n",
       "      <td>3.723708</td>\n",
       "      <td>6.646771</td>\n",
       "      <td>0.246091</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>DLDR_0016</th>\n",
       "      <td>4.603126</td>\n",
       "      <td>0.002788</td>\n",
       "      <td>2.608214</td>\n",
       "      <td>1.992446</td>\n",
       "      <td>5.079298</td>\n",
       "      <td>7.453528</td>\n",
       "      <td>2.274384</td>\n",
       "      <td>5.735367</td>\n",
       "      <td>5.394124</td>\n",
       "      <td>9.027927</td>\n",
       "      <td>...</td>\n",
       "      <td>2.934201</td>\n",
       "      <td>0.299770</td>\n",
       "      <td>0.488215</td>\n",
       "      <td>7.956485</td>\n",
       "      <td>5.527246</td>\n",
       "      <td>2.274384</td>\n",
       "      <td>3.722128</td>\n",
       "      <td>3.226652</td>\n",
       "      <td>6.739625</td>\n",
       "      <td>0.545930</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>DLDR_0004</th>\n",
       "      <td>4.003661</td>\n",
       "      <td>-0.178864</td>\n",
       "      <td>2.418699</td>\n",
       "      <td>2.287454</td>\n",
       "      <td>5.125878</td>\n",
       "      <td>6.943351</td>\n",
       "      <td>2.538993</td>\n",
       "      <td>6.049955</td>\n",
       "      <td>5.583037</td>\n",
       "      <td>8.243201</td>\n",
       "      <td>...</td>\n",
       "      <td>2.418699</td>\n",
       "      <td>0.217065</td>\n",
       "      <td>-0.519901</td>\n",
       "      <td>7.122512</td>\n",
       "      <td>3.978350</td>\n",
       "      <td>2.974088</td>\n",
       "      <td>3.280568</td>\n",
       "      <td>2.418699</td>\n",
       "      <td>6.827647</td>\n",
       "      <td>0.999473</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>DLDR_0165</th>\n",
       "      <td>5.286333</td>\n",
       "      <td>0.143691</td>\n",
       "      <td>0.332137</td>\n",
       "      <td>1.587791</td>\n",
       "      <td>5.827910</td>\n",
       "      <td>7.489948</td>\n",
       "      <td>1.225221</td>\n",
       "      <td>6.994423</td>\n",
       "      <td>6.261908</td>\n",
       "      <td>8.733452</td>\n",
       "      <td>...</td>\n",
       "      <td>2.368478</td>\n",
       "      <td>0.143691</td>\n",
       "      <td>0.389852</td>\n",
       "      <td>6.695064</td>\n",
       "      <td>3.291074</td>\n",
       "      <td>1.485611</td>\n",
       "      <td>2.862085</td>\n",
       "      <td>2.892352</td>\n",
       "      <td>7.434889</td>\n",
       "      <td>-3.697611</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>DLDR_0127</th>\n",
       "      <td>5.118729</td>\n",
       "      <td>-0.818750</td>\n",
       "      <td>0.897457</td>\n",
       "      <td>1.530400</td>\n",
       "      <td>5.446251</td>\n",
       "      <td>7.622416</td>\n",
       "      <td>0.897457</td>\n",
       "      <td>6.472366</td>\n",
       "      <td>5.832644</td>\n",
       "      <td>8.246698</td>\n",
       "      <td>...</td>\n",
       "      <td>2.137661</td>\n",
       "      <td>0.811301</td>\n",
       "      <td>1.128783</td>\n",
       "      <td>6.668899</td>\n",
       "      <td>3.631283</td>\n",
       "      <td>3.308569</td>\n",
       "      <td>2.881690</td>\n",
       "      <td>2.101816</td>\n",
       "      <td>7.391864</td>\n",
       "      <td>0.215197</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 527 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "              9         56        264       274       277       296    \\\n",
       "DLDR_0022  3.967031  0.177378  2.880522  2.254454  5.101756  7.696151   \n",
       "DLDR_0016  4.603126  0.002788  2.608214  1.992446  5.079298  7.453528   \n",
       "DLDR_0004  4.003661 -0.178864  2.418699  2.287454  5.125878  6.943351   \n",
       "DLDR_0165  5.286333  0.143691  0.332137  1.587791  5.827910  7.489948   \n",
       "DLDR_0127  5.118729 -0.818750  0.897457  1.530400  5.446251  7.622416   \n",
       "\n",
       "              309       340       351       389    ...     16641     16686  \\\n",
       "DLDR_0022  2.077214  5.845657  5.444621  8.076772  ...  2.825450  0.246091   \n",
       "DLDR_0016  2.274384  5.735367  5.394124  9.027927  ...  2.934201  0.299770   \n",
       "DLDR_0004  2.538993  6.049955  5.583037  8.243201  ...  2.418699  0.217065   \n",
       "DLDR_0165  1.225221  6.994423  6.261908  8.733452  ...  2.368478  0.143691   \n",
       "DLDR_0127  0.897457  6.472366  5.832644  8.246698  ...  2.137661  0.811301   \n",
       "\n",
       "              16715     16731     16762     16862     16886     16891  \\\n",
       "DLDR_0022  0.928350  7.735892  4.644785  2.335526  3.460071  3.723708   \n",
       "DLDR_0016  0.488215  7.956485  5.527246  2.274384  3.722128  3.226652   \n",
       "DLDR_0004 -0.519901  7.122512  3.978350  2.974088  3.280568  2.418699   \n",
       "DLDR_0165  0.389852  6.695064  3.291074  1.485611  2.862085  2.892352   \n",
       "DLDR_0127  1.128783  6.668899  3.631283  3.308569  2.881690  2.101816   \n",
       "\n",
       "              17074     17186  \n",
       "DLDR_0022  6.646771  0.246091  \n",
       "DLDR_0016  6.739625  0.545930  \n",
       "DLDR_0004  6.827647  0.999473  \n",
       "DLDR_0165  7.434889 -3.697611  \n",
       "DLDR_0127  7.391864  0.215197  \n",
       "\n",
       "[5 rows x 527 columns]"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_deg_test.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It's time for classification. I have used four types of classifiers throughout the project to ensure consistency. These classifiers are well-established in machine learning and are well-suited for this task. The classifiers used are: \n",
    "Logistic Regression, Support Vector Machine, Random Forest, and Multilayer Perceptron."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Logistic Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.8010912698412698\n",
      "0.7752136752136751\n"
     ]
    }
   ],
   "source": [
    "# Logistic Regression\n",
    "LR_model = LogisticRegression(solver='saga')\n",
    "LR_model.fit(df_deg, y_train)\n",
    "y_pred_LR = LR_model.predict(df_deg_test)\n",
    "LR_precision = precision_score(y_test, y_pred_LR, average='macro')\n",
    "LR_recall = recall_score(y_test, y_pred_LR, average='macro')\n",
    "print(LR_precision)\n",
    "print(LR_recall)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Support Vector Machine"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.8441558441558442\n",
      "0.8008547008547008\n"
     ]
    }
   ],
   "source": [
    "# Support Vector Machine\n",
    "SVM_model = SVC(kernel='linear', C=1)\n",
    "SVM_model.fit(df_deg, y_train)\n",
    "y_pred_SVM = SVM_model.predict(df_deg_test)\n",
    "SVM_precision = precision_score(y_test, y_pred_SVM, average='macro')\n",
    "SVM_recall = recall_score(y_test, y_pred_SVM, average='macro')\n",
    "print(SVM_precision)\n",
    "print(SVM_recall)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Random Forest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.7743589743589744\n",
      "0.7606837606837606\n"
     ]
    }
   ],
   "source": [
    "# Random Forest\n",
    "RF_model = RandomForestClassifier(random_state = 10101)\n",
    "RF_model.fit(df_deg, y_train)\n",
    "y_pred_RF = RF_model.predict(df_deg_test)\n",
    "RF_precision = precision_score(y_test, y_pred_RF, average='macro')\n",
    "RF_recall = recall_score(y_test, y_pred_RF, average='macro')\n",
    "print(RF_precision)\n",
    "print(RF_recall)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Multi Layer Perceptron"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.7317550505050505\n",
      "0.7051282051282052\n"
     ]
    }
   ],
   "source": [
    "# Multi Layer Perceptron\n",
    "MLP_model = MLPClassifier(hidden_layer_sizes=(100,), max_iter=300, activation='relu', solver='adam', random_state = 10101)\n",
    "MLP_model.fit(df_deg, y_train)\n",
    "y_pred_MLP = MLP_model.predict(df_deg_test)\n",
    "MLP_precision = precision_score(y_test, y_pred_MLP, average='macro')\n",
    "MLP_recall = recall_score(y_test, y_pred_MLP, average='macro')\n",
    "print(MLP_precision)\n",
    "print(MLP_recall)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "So far, we have obtained only a single result for each classifier, but these results are not statistically valid. To test for reproducibility, we have put the entire process into a loop to run it 100 times. Additionally, we created an R script to perform DE analysis automatically using subprocess. Letâ€™s run this cell and save the results for statistical analysis."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "iteration 0\n",
      "iteration 1\n",
      "iteration 2\n",
      "iteration 3\n",
      "iteration 4\n",
      "iteration 5\n",
      "iteration 6\n",
      "iteration 7\n",
      "iteration 8\n",
      "iteration 9\n",
      "iteration 10\n",
      "iteration 11\n",
      "iteration 12\n",
      "iteration 13\n",
      "iteration 14\n",
      "iteration 15\n",
      "iteration 16\n",
      "iteration 17\n",
      "iteration 18\n",
      "iteration 19\n",
      "iteration 20\n",
      "iteration 21\n",
      "iteration 22\n",
      "iteration 23\n",
      "iteration 24\n",
      "iteration 25\n",
      "iteration 26\n",
      "iteration 27\n",
      "iteration 28\n",
      "iteration 29\n",
      "iteration 30\n",
      "iteration 31\n",
      "iteration 32\n",
      "iteration 33\n",
      "iteration 34\n",
      "iteration 35\n",
      "iteration 36\n",
      "iteration 37\n",
      "iteration 38\n",
      "iteration 39\n",
      "iteration 40\n",
      "iteration 41\n",
      "iteration 42\n",
      "iteration 43\n",
      "iteration 44\n",
      "iteration 45\n",
      "iteration 46\n",
      "iteration 47\n",
      "iteration 48\n",
      "iteration 49\n",
      "iteration 50\n",
      "iteration 51\n",
      "iteration 52\n",
      "iteration 53\n",
      "iteration 54\n",
      "iteration 55\n",
      "iteration 56\n",
      "iteration 57\n",
      "iteration 58\n",
      "iteration 59\n",
      "iteration 60\n",
      "iteration 61\n",
      "iteration 62\n",
      "iteration 63\n",
      "iteration 64\n",
      "iteration 65\n",
      "iteration 66\n",
      "iteration 67\n",
      "iteration 68\n",
      "iteration 69\n",
      "iteration 70\n",
      "iteration 71\n",
      "iteration 72\n",
      "iteration 73\n",
      "iteration 74\n",
      "iteration 75\n",
      "iteration 76\n",
      "iteration 77\n",
      "iteration 78\n",
      "iteration 79\n",
      "iteration 80\n",
      "iteration 81\n",
      "iteration 82\n",
      "iteration 83\n",
      "iteration 84\n",
      "iteration 85\n",
      "iteration 86\n",
      "iteration 87\n",
      "iteration 88\n",
      "iteration 89\n",
      "iteration 90\n",
      "iteration 91\n",
      "iteration 92\n",
      "iteration 93\n",
      "iteration 94\n",
      "iteration 95\n",
      "iteration 96\n",
      "iteration 97\n",
      "iteration 98\n",
      "iteration 99\n"
     ]
    }
   ],
   "source": [
    "import subprocess\n",
    "\n",
    "# Load Data\n",
    "normal_counts = pd.read_csv('Normal.counts.voom.csv')\n",
    "meta_data = pd.read_csv('meta_data.csv')\n",
    "\n",
    "n_iterations = 300\n",
    "test_size = 0.3\n",
    "\n",
    "LR_precisions = []\n",
    "LR_recalls = []\n",
    "\n",
    "SVM_precisions = []\n",
    "SVM_recalls = []\n",
    "\n",
    "RF_precisions = []\n",
    "RF_recalls = []\n",
    "\n",
    "MLP_precisions = []\n",
    "MLP_recalls = []\n",
    "\n",
    "for i in range(100):\n",
    "    print('iteration',i)\n",
    "    X_train, X_test, y_train, y_test = train_test_split(normal_counts.iloc[0:,1:].T, meta_data['Simplified_class'], test_size=0.3, random_state = i)\n",
    "    X_train.T.to_csv('train_normal_counts.csv', index=False)\n",
    "    y_train.T.to_csv('train_meta_data.csv', index=False)\n",
    "\n",
    "    r_script_path = r\"q1r.R\"\n",
    "    rscript_path = r\"C:\\Program Files\\R\\R-4.2.1\\bin\\Rscript.exe\"\n",
    "    # Execute the R script\n",
    "    try:\n",
    "    \tsubprocess.run([rscript_path, r_script_path], capture_output=True, text=True)\n",
    "    except subprocess.CalledProcessError as e:\n",
    "    \tprint(f\"Error executing R script: {e}\")\n",
    "\n",
    "    #\n",
    "    subset_data = pd.read_csv('subset_data.csv')\n",
    "    selected_genes_R = subset_data.T.iloc[0,:].to_list()\n",
    "    selected_genes_Python = [int(i-1) for i in selected_genes_R ]\n",
    "    df_deg = subset_data.iloc[0:,1:].T\n",
    "    df_deg_test = X_test[selected_genes_Python]\n",
    "\n",
    "\n",
    "    # Logistic Regression\n",
    "    LR_model = LogisticRegression(solver='saga')\n",
    "    LR_model.fit(df_deg, y_train)\n",
    "    y_pred_LR = LR_model.predict(df_deg_test)\n",
    "    LR_precision = precision_score(y_test, y_pred_LR, average='macro')\n",
    "    LR_recall = recall_score(y_test, y_pred_LR, average='macro')\n",
    "    LR_precisions.append(LR_precision)\n",
    "    LR_recalls.append(LR_recall)\n",
    "\n",
    "    # Support Vector Machine\n",
    "    SVM_model = SVC(kernel='linear', C=1)\n",
    "    SVM_model.fit(df_deg, y_train)\n",
    "    y_pred_SVM = SVM_model.predict(df_deg_test)\n",
    "    SVM_precision = precision_score(y_test, y_pred_SVM, average='macro')\n",
    "    SVM_recall = recall_score(y_test, y_pred_SVM, average='macro')\n",
    "    SVM_precisions.append(SVM_precision)\n",
    "    SVM_recalls.append(SVM_recall)\n",
    "\n",
    "    # Random Forest\n",
    "    RF_model = RandomForestClassifier(random_state = i)\n",
    "    RF_model.fit(df_deg, y_train)\n",
    "    y_pred_RF = RF_model.predict(df_deg_test)\n",
    "    RF_precision = precision_score(y_test, y_pred_RF, average='macro')\n",
    "    RF_recall = recall_score(y_test, y_pred_RF, average='macro')\n",
    "    RF_precisions.append(RF_precision)\n",
    "    RF_recalls.append(RF_recall)\n",
    "\n",
    "    # Multi Layer Perceptron\n",
    "    MLP_model = MLPClassifier(hidden_layer_sizes=(100,), max_iter=300, activation='relu', solver='adam', random_state = i)\n",
    "    MLP_model.fit(df_deg, y_train)\n",
    "    y_pred_MLP = MLP_model.predict(df_deg_test)\n",
    "    MLP_precision = precision_score(y_test, y_pred_MLP, average='macro')\n",
    "    MLP_recall = recall_score(y_test, y_pred_MLP, average='macro')\n",
    "    MLP_precisions.append(MLP_precision)\n",
    "    MLP_recalls.append(MLP_recall)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Last but not least, we need to report the average and confidence interval for the results of each classifier. We will also create a bar plot to visually compare the results of the classifiers."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean Precision for Logistic Regression: 0.7636803304888079, 95% CI: [0.64076229 0.85890152]\n",
      "Mean Recall for Logistic Regression: 0.7645416569253737, 95% CI: [0.63156272 0.87401786]\n",
      "-------------------------------------------------------------------------------------------------\n",
      "Mean Precision for Support Vector Machine: 0.7743040927880918, 95% CI: [0.66116453 0.85674319]\n",
      "Mean Recall for Support Vector Machine: 0.7723320280185707, 95% CI: [0.65753472 0.86513971]\n",
      "-------------------------------------------------------------------------------------------------\n",
      "Mean Precision for Random Forest: 0.7860810773240244, 95% CI: [0.6725455  0.87525208]\n",
      "Mean Recall for Random Forest: 0.7867412414621653, 95% CI: [0.65607372 0.88233974]\n",
      "-------------------------------------------------------------------------------------------------\n",
      "Mean Precision for Multi Layer Perceptron: 0.7677514303520464, 95% CI: [0.65656233 0.85438582]\n",
      "Mean Recall for Multi Layer Perceptron: 0.7618658834643532, 95% CI: [0.6144042 0.8572071]\n"
     ]
    }
   ],
   "source": [
    "LR_mean_precision = np.mean(LR_precisions)\n",
    "LR_mean_recall = np.mean(LR_recalls)\n",
    "LR_precision_conf_interval = np.percentile(LR_precisions, [2.5, 97.5])\n",
    "LR_recall_conf_interval = np.percentile(LR_recalls, [2.5, 97.5])\n",
    "print(f'Mean Precision for Logistic Regression: {LR_mean_precision}, 95% CI: {LR_precision_conf_interval}')\n",
    "print(f'Mean Recall for Logistic Regression: {LR_mean_recall}, 95% CI: {LR_recall_conf_interval}')\n",
    "print(\"-------------------------------------------------------------------------------------------------\")\n",
    "\n",
    "SVM_mean_precision = np.mean(SVM_precisions)\n",
    "SVM_mean_recall = np.mean(SVM_recalls)\n",
    "SVM_precision_conf_interval = np.percentile(SVM_precisions, [2.5, 97.5])\n",
    "SVM_recall_conf_interval = np.percentile(SVM_recalls, [2.5, 97.5])\n",
    "print(f'Mean Precision for Support Vector Machine: {SVM_mean_precision}, 95% CI: {SVM_precision_conf_interval}')\n",
    "print(f'Mean Recall for Support Vector Machine: {SVM_mean_recall}, 95% CI: {SVM_recall_conf_interval}')\n",
    "print(\"-------------------------------------------------------------------------------------------------\")\n",
    "\n",
    "RF_mean_precision = np.mean(RF_precisions)\n",
    "RF_mean_recall = np.mean(RF_recalls)\n",
    "RF_precision_conf_interval = np.percentile(RF_precisions, [2.5, 97.5])\n",
    "RF_recall_conf_interval = np.percentile(RF_recalls, [2.5, 97.5])\n",
    "print(f'Mean Precision for Random Forest: {RF_mean_precision}, 95% CI: {RF_precision_conf_interval}')\n",
    "print(f'Mean Recall for Random Forest: {RF_mean_recall}, 95% CI: {RF_recall_conf_interval}')\n",
    "print(\"-------------------------------------------------------------------------------------------------\")\n",
    "\n",
    "MLP_mean_precision = np.mean(MLP_precisions)\n",
    "MLP_mean_recall = np.mean(MLP_recalls)\n",
    "MLP_precision_conf_interval = np.percentile(MLP_precisions, [2.5, 97.5])\n",
    "MLP_recall_conf_interval = np.percentile(MLP_recalls, [2.5, 97.5])\n",
    "print(f'Mean Precision for Multi Layer Perceptron: {MLP_mean_precision}, 95% CI: {MLP_precision_conf_interval}')\n",
    "print(f'Mean Recall for Multi Layer Perceptron: {MLP_mean_recall}, 95% CI: {MLP_recall_conf_interval}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "id": "r9rhRcfoNGaS"
   },
   "outputs": [],
   "source": [
    "model_results = {\n",
    "    'RandomForest': {\n",
    "        'mean_precision': RF_mean_precision,\n",
    "        'precision_ci': RF_precision_conf_interval,\n",
    "        'mean_recall': RF_mean_recall,\n",
    "        'recall_ci': RF_precision_conf_interval\n",
    "    },\n",
    "    'SVM': {\n",
    "        'mean_precision': SVM_mean_precision,\n",
    "        'precision_ci': SVM_precision_conf_interval,\n",
    "        'mean_recall': SVM_mean_recall,\n",
    "        'recall_ci': SVM_precision_conf_interval\n",
    "    },\n",
    "        'LogisticRegression': {\n",
    "        'mean_precision': LR_mean_precision,\n",
    "        'precision_ci': LR_precision_conf_interval,\n",
    "        'mean_recall': LR_mean_recall,\n",
    "        'recall_ci': LR_precision_conf_interval\n",
    "    },\n",
    "    'MLP': {\n",
    "        'mean_precision': MLP_mean_precision,\n",
    "        'precision_ci': MLP_precision_conf_interval,\n",
    "        'mean_recall': MLP_mean_recall,\n",
    "        'recall_ci': MLP_precision_conf_interval\n",
    "    }\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "id": "xh-BCMMtN6gw"
   },
   "outputs": [],
   "source": [
    "models = list(model_results.keys())\n",
    "mean_precisions = [model_results[model]['mean_precision'] for model in models]\n",
    "precision_cis = [model_results[model]['precision_ci'] for model in models]\n",
    "mean_recalls = [model_results[model]['mean_recall'] for model in models]\n",
    "recall_cis = [model_results[model]['recall_ci'] for model in models]\n",
    "precision_errors = np.array([[mean - ci[0], ci[1] - mean] for mean, ci in zip(mean_precisions, precision_cis)]).T\n",
    "recall_errors = np.array([[mean - ci[0], ci[1] - mean] for mean, ci in zip(mean_recalls, recall_cis)]).T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 607
    },
    "id": "CYTiPju6M1a9",
    "outputId": "d74d8f6c-d8a0-4015-c278-1f67d10289f6"
   },
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 1400x600 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "fig, ax = plt.subplots(1, 2, figsize=(14, 6))\n",
    "\n",
    "# Plot precision\n",
    "ax[0].bar(models, mean_precisions, yerr=precision_errors, capsize=5, color='skyblue')\n",
    "ax[0].set_title('Mean Precision with 95% Confidence Interval')\n",
    "ax[0].set_ylabel('Precision')\n",
    "ax[0].set_ylim([0.5, 1])\n",
    "ax[0].set_xticklabels(models, rotation=45, ha=\"right\")\n",
    "\n",
    "# Plot recall\n",
    "ax[1].bar(models, mean_recalls, yerr=recall_errors, capsize=5, color='lightgreen')\n",
    "ax[1].set_title('Mean Recall with 95% Confidence Interval')\n",
    "ax[1].set_ylabel('Recall')\n",
    "ax[1].set_ylim([0.5, 1])\n",
    "ax[1].set_xticklabels(models, rotation=45, ha=\"right\")\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here are the final results: as you can see, the performance of the classifiers is very similar, with none of them significantly outperforming the others. However, Random Forest exhibits slightly higher precision and recall compared to the other models."
   ]
  }
 ],
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
